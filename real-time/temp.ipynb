{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83d2d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import glob\n",
    "import plotly.graph_objects as go\n",
    "from meteofrance_api import MeteoFranceClient\n",
    "\n",
    "%matplotlib inline\n",
    "# Set notebook mode to work in offline\n",
    "pio.renderers.default = 'iframe+pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccebbc9",
   "metadata": {},
   "source": [
    "## Données Méteos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d90f841",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = \"../coord_stations_exploitables.txt\"\n",
    "\n",
    "df = pd.read_csv(file_path, sep=',', names=['Latitude', 'Longitude'])\n",
    "\n",
    "# Initialisation du client MeteoFrance\n",
    "client = MeteoFranceClient()\n",
    "\n",
    "def get_precipitation(lat, lon, client):\n",
    "    try:\n",
    "        obs = client.get_rain(lat, lon)\n",
    "        forecast = obs.forecast\n",
    "        total_rain = sum(item['rain'] for item in forecast)\n",
    "        avg = total_rain / len(forecast)\n",
    "        return forecast, forecast[0]['rain']        \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la récupération des données météorologiques : {e}\")\n",
    "        return [], 0\n",
    "\n",
    "df['Forecast'], df['Precipitation'] = zip(\n",
    "    *df.apply(lambda row: get_precipitation(row['Latitude'], row['Longitude'], client), axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7563843d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Forecast</th>\n",
       "      <th>Precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.564377</td>\n",
       "      <td>7.528982</td>\n",
       "      <td>[{'dt': 1700840400, 'rain': 1, 'desc': 'Temps ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.221808</td>\n",
       "      <td>7.647875</td>\n",
       "      <td>[{'dt': 1700840400, 'rain': 1, 'desc': 'Temps ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.296112</td>\n",
       "      <td>7.654202</td>\n",
       "      <td>[{'dt': 1700840400, 'rain': 1, 'desc': 'Temps ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.592540</td>\n",
       "      <td>7.802871</td>\n",
       "      <td>[{'dt': 1700840400, 'rain': 1, 'desc': 'Temps ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.488084</td>\n",
       "      <td>7.392949</td>\n",
       "      <td>[{'dt': 1700840400, 'rain': 1, 'desc': 'Temps ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>42.229485</td>\n",
       "      <td>9.437795</td>\n",
       "      <td>[{'dt': 1700840400, 'rain': 1, 'desc': 'Temps ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2407</th>\n",
       "      <td>42.103244</td>\n",
       "      <td>9.260356</td>\n",
       "      <td>[{'dt': 1700840400, 'rain': 1, 'desc': 'Temps ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>41.863776</td>\n",
       "      <td>9.370376</td>\n",
       "      <td>[{'dt': 1700840400, 'rain': 1, 'desc': 'Temps ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>41.706231</td>\n",
       "      <td>9.333949</td>\n",
       "      <td>[{'dt': 1700840400, 'rain': 1, 'desc': 'Temps ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2410</th>\n",
       "      <td>41.596406</td>\n",
       "      <td>9.237163</td>\n",
       "      <td>[{'dt': 1700840400, 'rain': 1, 'desc': 'Temps ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2411 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Latitude  Longitude                                           Forecast  \\\n",
       "0     47.564377   7.528982  [{'dt': 1700840400, 'rain': 1, 'desc': 'Temps ...   \n",
       "1     48.221808   7.647875  [{'dt': 1700840400, 'rain': 1, 'desc': 'Temps ...   \n",
       "2     48.296112   7.654202  [{'dt': 1700840400, 'rain': 1, 'desc': 'Temps ...   \n",
       "3     48.592540   7.802871  [{'dt': 1700840400, 'rain': 1, 'desc': 'Temps ...   \n",
       "4     47.488084   7.392949  [{'dt': 1700840400, 'rain': 1, 'desc': 'Temps ...   \n",
       "...         ...        ...                                                ...   \n",
       "2406  42.229485   9.437795  [{'dt': 1700840400, 'rain': 1, 'desc': 'Temps ...   \n",
       "2407  42.103244   9.260356  [{'dt': 1700840400, 'rain': 1, 'desc': 'Temps ...   \n",
       "2408  41.863776   9.370376  [{'dt': 1700840400, 'rain': 1, 'desc': 'Temps ...   \n",
       "2409  41.706231   9.333949  [{'dt': 1700840400, 'rain': 1, 'desc': 'Temps ...   \n",
       "2410  41.596406   9.237163  [{'dt': 1700840400, 'rain': 1, 'desc': 'Temps ...   \n",
       "\n",
       "      Precipitation  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "...             ...  \n",
       "2406              1  \n",
       "2407              1  \n",
       "2408              1  \n",
       "2409              1  \n",
       "2410              1  \n",
       "\n",
       "[2411 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3528354",
   "metadata": {},
   "source": [
    "## Données Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef91cee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 3466 stations en fonctionnement.\n"
     ]
    }
   ],
   "source": [
    "url_stations = \"http://hubeau.eaufrance.fr/api/v1/hydrometrie/referentiel/stations\"\n",
    "\n",
    "response_stations = requests.get(url_stations, params={\"size\": 6000})\n",
    "if response_stations.status_code == '200' or '206': # status codes are detailed on the website\n",
    "    data_stations = response_stations.json()\n",
    "    data_stations = pd.DataFrame(data_stations[\"data\"])\n",
    "else:\n",
    "    print(f\"La requête a échoué avec le code d'état {response_stations.status_code}\")\n",
    "\n",
    "# We check the names of the columns that contain at least 50% of null values\n",
    "data_stations.isnull().sum()\n",
    "\n",
    "# We remove the columns that contain at least 50% of null values\n",
    "data_stations = data_stations.dropna(axis=1, thresh=int(0.5*len(data_stations)))\n",
    "\n",
    "# We remove every row that is not in metropolitan france\n",
    "regions_in_metropolitan_france = ['GRAND EST', 'HAUTS-DE-FRANCE', 'BOURGOGNE-FRANCHE-COMTE', 'ILE-DE-FRANCE', 'CENTRE-VAL DE LOIRE', 'NORMANDIE', 'BRETAGNE', 'PAYS DE LA LOIRE', 'AUVERGNE-RHONE-ALPES', 'OCCITANIE', 'NOUVELLE-AQUITAINE', \"PROVENCE-ALPES-COTE D'AZUR\", 'CORSE']\n",
    "data_stations = data_stations[data_stations[\"libelle_region\"].isin(regions_in_metropolitan_france)]\n",
    "\n",
    "# Next, we remove every row where the corresponding station is not active\n",
    "data_stations = data_stations[data_stations[\"en_service\"] == True]\n",
    "\n",
    "# We remove every row where the longitude is between -15 and 40\n",
    "data_stations = data_stations[(data_stations[\"longitude_station\"] > -15) & (data_stations[\"longitude_station\"] < 40)]\n",
    "\n",
    "print(\"Il y a\",len(data_stations),\"stations en fonctionnement.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f03d9df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 2588  stations pour lesquelles on connait la moyenne des observations de débit des 25 dernières années.\n"
     ]
    }
   ],
   "source": [
    "dossier = '../data_limites'\n",
    "\n",
    "fichiers_csv = glob.glob(dossier + '/data*')\n",
    "\n",
    "codes_sites_A = []\n",
    "for fichier in fichiers_csv:\n",
    "    codes_sites_A.append(fichier.split(\"_\")[-1])\n",
    "\n",
    "print(\"Il y a\",len(codes_sites_A),\" stations pour lesquelles on connait la moyenne des observations de débit des 25 dernières années.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4772b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 2778 stations pour lesquelles on a le seuil limite maximum (hauteur)\n"
     ]
    }
   ],
   "source": [
    "# On récupère les seuils limites de hauteur\n",
    "\n",
    "with open(\"../limites_H.txt\",'r') as file:\n",
    "    seuils_H = {}\n",
    "    for line in file:\n",
    "        cle, valeur = line.strip().split(':')        \n",
    "        seuils_H[cle] = valeur\n",
    "\n",
    "        \n",
    "code_sites_H = list(seuils_H.keys())\n",
    "print(\"Il y a\",len(seuils_H),\"stations pour lesquelles on a le seuil limite maximum (hauteur)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69c62668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 2655 stations pour lesquelles on a le seuil limite maximum (débit)\n"
     ]
    }
   ],
   "source": [
    "# On récupère les seuils limites de débit\n",
    "\n",
    "with open(\"../limites_Q.txt\",'r') as file:\n",
    "    seuils_Q = {}\n",
    "    for line in file:\n",
    "        cle, valeur = line.strip().split(':')        \n",
    "        seuils_Q[cle] = valeur\n",
    "\n",
    "        \n",
    "code_sites_Q = list(seuils_Q.keys())\n",
    "print(\"Il y a\",len(seuils_Q),\"stations pour lesquelles on a le seuil limite maximum (débit)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d2c5055c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 2411  stations exploitables\n"
     ]
    }
   ],
   "source": [
    "data_stations_final = data_stations.loc[data_stations['code_station'].isin(codes_sites_A)] # Stations dont on a les observations passées\n",
    "data_stations_final = data_stations_final.loc[data_stations_final['code_station'].isin(code_sites_H)] # Stations dont on a les seuils_H\n",
    "data_stations_final = data_stations_final.loc[data_stations_final['code_station'].isin(code_sites_Q)] # Stations dont on a les seuils_Q\n",
    "print(\"Il y a\",len(data_stations_final),\" stations exploitables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "38a31b2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_stations_final = data_stations_final[[\"code_site\", \"code_station\", \"longitude_station\", \"latitude_station\", \n",
    "                                           \"influence_locale_station\", \"code_commune_station\", \"code_departement\", \n",
    "                                           \"code_region\", \"code_cours_eau\", \"code_regime_station\", \n",
    "                                           \"qualification_donnees_station\", \"code_finalite_station\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1a21e5",
   "metadata": {},
   "source": [
    "#### On encode les variables catégoriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dd2ecd81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_site</th>\n",
       "      <th>code_site_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>A0220200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>A0410300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>A0530742</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>A0610050</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>A1000030</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    code_site  code_site_encoded\n",
       "263  A0220200                  0\n",
       "275  A0410300                  1\n",
       "283  A0530742                  2\n",
       "288  A0610050                  3\n",
       "289  A1000030                  4"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Créer une instance de LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encoder la colonne 'code_site'\n",
    "data_stations_final['code_site_encoded'] = label_encoder.fit_transform(data_stations_final['code_site'])\n",
    "\n",
    "# Encoder la colonne 'code_station'\n",
    "data_stations_final['code_station_encoded'] = label_encoder.fit_transform(data_stations_final['code_station'])\n",
    "\n",
    "# Ecoder 'code_commune_station'\n",
    "data_stations_final['code_cours_eau_encoded'] = label_encoder.fit_transform(data_stations_final['code_cours_eau'])\n",
    "\n",
    "data_stations_final[['code_site','code_site_encoded']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b8f4ed8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2411 entries, 263 to 5862\n",
      "Data columns (total 15 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   code_site                      2411 non-null   object \n",
      " 1   code_station                   2411 non-null   object \n",
      " 2   longitude_station              2411 non-null   float64\n",
      " 3   latitude_station               2411 non-null   float64\n",
      " 4   influence_locale_station       2258 non-null   float64\n",
      " 5   code_commune_station           2411 non-null   object \n",
      " 6   code_departement               2411 non-null   object \n",
      " 7   code_region                    2411 non-null   object \n",
      " 8   code_cours_eau                 2411 non-null   object \n",
      " 9   code_regime_station            2411 non-null   int64  \n",
      " 10  qualification_donnees_station  2411 non-null   int64  \n",
      " 11  code_finalite_station          2284 non-null   float64\n",
      " 12  code_site_encoded              2411 non-null   int32  \n",
      " 13  code_station_encoded           2411 non-null   int32  \n",
      " 14  code_cours_eau_encoded         2411 non-null   int32  \n",
      "dtypes: float64(4), int32(3), int64(2), object(6)\n",
      "memory usage: 273.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data_stations_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3e51e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model_v0 = data_stations_final[[\"code_site_encoded\", \"code_station_encoded\", \"longitude_station\", \"latitude_station\", \n",
    "                                           \"influence_locale_station\", \"code_cours_eau_encoded\",                                           \n",
    "                                           \"qualification_donnees_station\", \"code_finalite_station\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3d48dd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2411 entries, 263 to 5862\n",
      "Data columns (total 8 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   code_site_encoded              2411 non-null   int32  \n",
      " 1   code_station_encoded           2411 non-null   int32  \n",
      " 2   longitude_station              2411 non-null   float64\n",
      " 3   latitude_station               2411 non-null   float64\n",
      " 4   influence_locale_station       2258 non-null   float64\n",
      " 5   code_cours_eau_encoded         2411 non-null   int32  \n",
      " 6   qualification_donnees_station  2411 non-null   int64  \n",
      " 7   code_finalite_station          2284 non-null   float64\n",
      "dtypes: float64(4), int32(3), int64(1)\n",
      "memory usage: 141.3 KB\n"
     ]
    }
   ],
   "source": [
    "data_model_v0.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6510e7a3",
   "metadata": {},
   "source": [
    "#### Pour combler les valeurs manquantes on applique un Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cac9cdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data_model_temp = data_model_v0.drop('code_finalite_station',axis=1).reset_index(drop=True)\n",
    "\n",
    "nul_rows = data_model_temp[data_model_temp['influence_locale_station'].isna()]\n",
    "other_rows = data_model_temp.drop(nul_rows.index)\n",
    "\n",
    "X_train = other_rows.drop('influence_locale_station',axis=1).reset_index(drop=True)\n",
    "y_train = other_rows['influence_locale_station']\n",
    "\n",
    "X_test = nul_rows.drop('influence_locale_station',axis=1).reset_index(drop=True)\n",
    "\n",
    "# Standardiser les caractéristiques\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Créer et entraîner le modèle\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Faire des prédictions et évaluer le modèle\n",
    "y_pred = model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "785e6382",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model_v1 = data_model_v0.copy()\n",
    "data_model_v1.loc[data_model_v1['influence_locale_station'].isna(), 'influence_locale_station'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4e6c639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nul_rows = data_model_v1[data_model_v1['code_finalite_station'].isna()]\n",
    "other_rows = data_model_v1.drop(nul_rows.index)\n",
    "\n",
    "X_train = other_rows.drop('code_finalite_station',axis=1).reset_index(drop=True)\n",
    "y_train = other_rows['code_finalite_station']\n",
    "\n",
    "X_test = nul_rows.drop('code_finalite_station',axis=1).reset_index(drop=True)\n",
    "\n",
    "# Standardiser les caractéristiques\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Créer et entraîner le modèle\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Faire des prédictions et évaluer le modèle\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "aba7bfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model_v2 = data_model_v1.copy()\n",
    "data_model_v2.loc[data_model_v2['code_finalite_station'].isna(), 'code_finalite_station'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2d8fd27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2411 entries, 263 to 5862\n",
      "Data columns (total 8 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   code_site_encoded              2411 non-null   int32  \n",
      " 1   code_station_encoded           2411 non-null   int32  \n",
      " 2   longitude_station              2411 non-null   float64\n",
      " 3   latitude_station               2411 non-null   float64\n",
      " 4   influence_locale_station       2411 non-null   float64\n",
      " 5   code_cours_eau_encoded         2411 non-null   int32  \n",
      " 6   qualification_donnees_station  2411 non-null   int64  \n",
      " 7   code_finalite_station          2411 non-null   float64\n",
      "dtypes: float64(4), int32(3), int64(1)\n",
      "memory usage: 205.8 KB\n"
     ]
    }
   ],
   "source": [
    "data_model_v2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092d7f90",
   "metadata": {},
   "source": [
    "### Données Hydrométriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d49197f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requete 1 : status code: 200\n",
      "Requete 2 : status code: 200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[145], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m         file_data\u001b[38;5;241m.\u001b[39mextend(data)\n\u001b[0;32m     36\u001b[0m         file\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)            \n\u001b[1;32m---> 37\u001b[0m         \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLa requête \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnombre_requetes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m a échoué avec le code d\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124métat \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Programmes\\anaconda3\\envs\\PythonForDataAnalysis\\lib\\json\\__init__.py:180\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m--> 180\u001b[0m     \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "url = \"http://hubeau.eaufrance.fr/api/v1/hydrometrie/observations_tr\"\n",
    "stations = data_stations_final['code_station'].tolist()\n",
    "\n",
    "date2 = datetime(2018, 11, 24, 0, 0, 0) # On récupères toutes les observations des 5 dernières années\n",
    "date = datetime.now()-timedelta(hours=12)\n",
    "date = date.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "data_hydro = pd.DataFrame()\n",
    "nombre_requetes = 0\n",
    "\n",
    "for i in range(0,len(stations),75):\n",
    "    params = {\n",
    "        \"code_entite\": stations[i:i+75], # station code    \n",
    "        \"date_debut_obs\": date,        \n",
    "        \"grandeur_hydro\": ['Q','H'], # hydrometric variables choosen\n",
    "        \"size\": 20000        \n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    nombre_requetes+=1\n",
    "    print(f\"Requete {nombre_requetes} : status code:\",response.status_code)\n",
    "    \n",
    "    if response.status_code == (200 or 206):\n",
    "        data = response.json()['data']\n",
    "        \n",
    "        with open('historic_data_hydro.json', 'r+') as file:\n",
    "            try:\n",
    "                file_data = json.load(file)\n",
    "            except json.JSONDecodeError:\n",
    "                file_data = []\n",
    "\n",
    "            file_data.extend(data)\n",
    "            file.seek(0)            \n",
    "            json.dump(file_data, file, indent=4)\n",
    "            \n",
    "    else:\n",
    "        print(f\"La requête {nombre_requetes} a échoué avec le code d'état {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9289b54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
